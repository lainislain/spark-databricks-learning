{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# S1 J5 ? Delta Lake (Write + Read)\n",
        "\n",
        "This notebook writes a Delta table and reads it back.\n",
        "\n",
        "If you are running locally and Delta is missing, install it first:\n",
        "- `pip install delta-spark`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"delta-lake-demo\")\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "    .getOrCreate()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "data_path = \"../../data/example.csv\"\n",
        "delta_path = \"../../data/delta/users\"\n",
        "\n",
        "raw = (\n",
        "    spark.read\n",
        "    .option(\"header\", True)\n",
        "    .option(\"inferSchema\", True)\n",
        "    .csv(data_path)\n",
        ")\n",
        "\n",
        "silver = (\n",
        "    raw\n",
        "    .withColumn(\"signup_date\", F.to_date(\"signup_date\"))\n",
        "    .withColumn(\"spend\", F.col(\"spend\").cast(\"double\"))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write Delta table\n",
        "(\n",
        "    silver\n",
        "    .write\n",
        "    .format(\"delta\")\n",
        "    .mode(\"overwrite\")\n",
        "    .save(delta_path)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read Delta table\n",
        "delta_df = spark.read.format(\"delta\").load(delta_path)\n",
        "delta_df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register as a table for SQL queries (optional)\n",
        "spark.sql(f\"DROP TABLE IF EXISTS users_delta\")\n",
        "spark.sql(f\"CREATE TABLE users_delta USING DELTA LOCATION '{delta_path}'\")\n",
        "\n",
        "spark.sql(\"SELECT plan, COUNT(*) AS users, ROUND(SUM(spend), 2) AS total_spend FROM users_delta GROUP BY plan\").show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}